{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "name": "Train_Test_Splits_Regularization_Exercises-ANSWERS",
    "notebookId": 2125319687183944,
    "colab": {
      "name": "ml_assignment1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/assignment1/ml_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "exxTxlIdTB3L",
        "colab_type": "text"
      },
      "source": [
        "# ITI103: Essentials of Machine Learning - Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "qS7fHzUeTB3M",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this assignment, you will work a data set based on [housing prices in Ames, Iowa](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). It is a modernized alternative to the well-known Boston Housing dataset. \n",
        "\n",
        "You may access the dataset from [https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignment1/data/ames_housing_prices.csv](https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignment1/data/ames_housing_prices.csv) For a detailed description of each field (feature), you can refer to the following [file](data/data_description.txt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "Y9CGm2OgTB3N",
        "colab_type": "text"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "* Import the data using Pandas and examine the shape. There are 79 feature columns plus the predictor, the sale price (`SalePrice`). \n",
        "* There are three different types: integers (`int64`), floats (`float64`), and strings (`object`, categoricals). Examine how many there are of each data type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "O71PVNVLTB3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## START YOUR CODE\n",
        "\n",
        "# Import the data using the file path\n",
        "\n",
        "\n",
        "# examine the shape \n",
        "\n",
        "\n",
        "# Display value counts of each data type\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "V6TH2a6mTB3T",
        "colab_type": "text"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Find out how many columns are categorical (hint: string) columns and if you were to one-hot-encode, how many extra columns are created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "xOFa41z3TB3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## START YOUR CODE\n",
        "\n",
        "# Select the object (string) columns\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "FWXQFeMWTB3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## START YOUR CODE\n",
        "\n",
        "# Determine how many extra columns would be created\n",
        "\n",
        "\n",
        "# No need to encode if there is only one value\n",
        "\n",
        "\n",
        "## END YOUR CODE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "RT2vnRP-TB3c",
        "colab_type": "text"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Create a new data set where all of the above categorical features will be one-hot encoded. We can fit this data and see how it affects the results.\n",
        "\n",
        "* Used the dataframe `.copy()` method to create a completely separate copy of the dataframe for one-hot encoding\n",
        "* On this new dataframe, one-hot encode each of the appropriate columns and add it back to the dataframe. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "FrP8lg5aTB3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "## START YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "# one-hot-encode the appropriate columns\n",
        "\n",
        "\n",
        "# add back to the dataframe\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "48z7AaTtTB3g",
        "colab_type": "text"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "* Create train and test splits of both data sets. To ensure the data gets split the same way, use the same `random_state` in each of the two splits.\n",
        "* Decide if you need to do Stratified splitting. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "1DhyLUwlTB3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## START YOUR CODE HERE\n",
        "\n",
        "\n",
        "## END YOUR CODE\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "dBHECC6NTB3k",
        "colab_type": "text"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "* Scale the all the numerical (non OHE) features using one of the following: `StandardScaler`, `MinMaxScaler`\n",
        "* Be sure to fit the scaler on *ONLY* the training data, but then apply it to both the train and test data identically.\n",
        "* Optional: You may also want to calculate the skew of your numeric features and decide if you need to do log transform. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "srRkvT2ZTB3l",
        "colab_type": "text"
      },
      "source": [
        "Note that the error values on the one-hot encoded data are very different for the train and test data. In particular, the errors on the test data are much higher. Based on the lecture, this is because the one-hot encoded model is overfitting the data. We will learn how to deal with issues like this in the next lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhW1SNXuTB3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## START YOUR CODE HERE\n",
        "\n",
        "\n",
        "## END YOUR CODE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVnd4iNPTB3p",
        "colab_type": "text"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "* Fit a basic linear regression model on the training data. \n",
        "* Calculate the mean squared error on both the train and test sets for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFD0lAnOTB3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## START YOUR CODE HERE\n",
        "\n",
        "\n",
        "## END YOUR CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "_4Xl4cCnTB3t",
        "colab_type": "text"
      },
      "source": [
        "## Question 7\n",
        "\n",
        "Plot predictions vs actual the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "s1oqww5fTB3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "## START YOUR CODE HERE\n",
        "\n",
        "\n",
        "## END YOUR CODE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P0amO1xTB3w",
        "colab_type": "text"
      },
      "source": [
        "## Question 8\n",
        "\n",
        "What can you conclude from the train and test set predictions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI7zXWyjTB3x",
        "colab_type": "text"
      },
      "source": [
        "**Your answer**: \n"
      ]
    }
  ]
}